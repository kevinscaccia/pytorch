{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Model Training from Scratch Pytorch (Nano-GPT)\n",
    "\n",
    "- https://github.com/google/sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the tiny shakespeare dataset\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preprocess\n",
    "- Define vocabulary (Char-level)\n",
    "- Create tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary(65): ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "corpus = open('input.txt','r').read()\n",
    "chars = sorted(list(set(corpus)))\n",
    "VOCAB_SIZE = len(chars)\n",
    "print(f'Vocabulary({VOCAB_SIZE}):', chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence \"hello scaccia!\" tokenized: [46, 43, 50, 50, 53, 1, 57, 41, 39, 41, 41, 47, 39, 2]\n",
      "Token list [46, 43, 50, 50, 53, 1, 58, 53, 49, 43, 52, 57] decoded: \"hello tokens\"\n"
     ]
    }
   ],
   "source": [
    "class Tokenizer():\n",
    "    def __init__(self):\n",
    "        self.char_to_int_map = {c:i for i,c in enumerate(chars)}\n",
    "        self.int_to_char_map = {i:c for c,i in self.char_to_int_map.items()} # reverse map\n",
    "        # self.oov = \n",
    "    def encode(self, txt):\n",
    "        tokens = [self.char_to_int_map[c] for c in txt]\n",
    "        return tokens\n",
    "    def decode(self, tokens):\n",
    "        chars = [self.int_to_char_map[t] for t in tokens]\n",
    "        return ''.join(chars) # list to str\n",
    "\n",
    "    \n",
    "    \n",
    "tokenizer = Tokenizer()\n",
    "sentence = 'hello scaccia!'\n",
    "token_list = [46, 43, 50, 50, 53, 1, 58, 53, 49, 43, 52, 57]\n",
    "print(f'Sentence \"{sentence}\" tokenized: {tokenizer.encode(sentence)}')\n",
    "print(f'Token list {token_list} decoded: \"{tokenizer.decode(token_list)}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47])\n",
      "Corpus Len: 1115394 tokens\n",
      "Train Len: 1003854 tokens\n",
      "Validation Len: 111540 tokens\n"
     ]
    }
   ],
   "source": [
    "corpus_tensor = torch.tensor(tokenizer.encode(corpus), dtype=torch.long)\n",
    "print(corpus_tensor[:10])\n",
    "print(f'Corpus Len: {len(corpus_tensor)} tokens')\n",
    "#\n",
    "split_point = int(len(corpus_tensor)*0.9) #90% for train\n",
    "train_data = corpus_tensor[:split_point]\n",
    "validation_data = corpus_tensor[split_point:]\n",
    "#\n",
    "print(f'Train Len: {len(train_data)} tokens')\n",
    "print(f'Validation Len: {len(validation_data)} tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instance Sampling\n",
    "- block, context, chunk, sample,  qetc..\n",
    "-> maximum context length\n",
    "\n",
    "- O processo de criacao das instancias de treinamento supervisionadas (predict next word) amostra pequenos blocos de tokens do corpus original. Esses blocos são convertidos em varias instancias do tamanho 1 ate block_size-1. \n",
    "- a motivação é fazer com que o modelo seja acostumado a tomar entradas tao pequenas quanto 1 token e tao grandes quanto block_size. Para que no momento de inferencia ele esteja acostumado com sentencas de tamanhos variados.\n",
    "\n",
    "1. Amostra aleatoriamente da base um bloco de tokens de tamanho CONTEXT_LENGTH(tamanho maximo contexto )\n",
    "2. 33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35, 36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
      "        [77, 78, 79, 80, 81, 82, 83, 84, 85, 86],\n",
      "        [72, 73, 74, 75, 76, 77, 78, 79, 80, 81],\n",
      "        [ 8,  9, 10, 11, 12, 13, 14, 15, 16, 17]])\n",
      "tensor([[36, 37, 38, 39, 40, 41, 42, 43, 44, 45],\n",
      "        [78, 79, 80, 81, 82, 83, 84, 85, 86, 87],\n",
      "        [73, 74, 75, 76, 77, 78, 79, 80, 81, 82],\n",
      "        [ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]])\n",
      "Example (first sample of batch):\n",
      "For input [35] the target is 36\n",
      "For input [35 36] the target is 37\n",
      "For input [35 36 37] the target is 38\n",
      "For input [35 36 37 38] the target is 39\n",
      "For input [35 36 37 38 39] the target is 40\n",
      "For input [35 36 37 38 39 40] the target is 41\n",
      "For input [35 36 37 38 39 40 41] the target is 42\n",
      "For input [35 36 37 38 39 40 41 42] the target is 43\n",
      "For input [35 36 37 38 39 40 41 42 43] the target is 44\n",
      "For input [35 36 37 38 39 40 41 42 43 44] the target is 45\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(177)\n",
    "\n",
    "CONTEXT_LENGTH = 10\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "def get_batch(data, batch_size, context_len, verbose=False):\n",
    "    # generate start index of all batches\n",
    "    start_ixs = torch.randint(low=0, high=len(data)-context_len, size=(batch_size,))\n",
    "    # all batches at once\n",
    "    if verbose: print(f'This batch start indexes: {start_ixs}')\n",
    "    # print('first batch:', data[start_ixs[0]:start_ixs[0]+context_len])\n",
    "    batch_x = torch.vstack([data[i:i+context_len] for i in start_ixs]) # stack each sample in a row\n",
    "    batch_y = torch.vstack([data[i+1:i+context_len+1] for i in start_ixs]) # aligned\n",
    "\n",
    "    return batch_x, batch_y\n",
    "\n",
    "\n",
    "X, Y = get_batch(torch.tensor(list(range(0,100))), BATCH_SIZE, CONTEXT_LENGTH)\n",
    "print(X)\n",
    "print(Y)\n",
    "# each row in the batch is in really 10 instances (varying the context len)\n",
    "print('Example (first sample of batch):')\n",
    "for t in range(CONTEXT_LENGTH): # in time dimension(sequence)\n",
    "    _x = X[0][:t+1].numpy()\n",
    "    _y = Y[0][t].numpy()\n",
    "    print(f'For input {_x} the target is {_y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## NanoGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from self_attention import SelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_x, train_batch_y = get_batch(train_data, BATCH_SIZE, CONTEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 65])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NanoGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, block_size, lr=1e-3):\n",
    "        super(NanoGPT, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.attention_layer = SelfAttention(embedding_dim, embedding_dim, block_size)\n",
    "        self.linear_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "        #\n",
    "        self.optimizer = torch.optim.AdamW(self.parameters(), lr=lr)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        embs = self.embedding_layer(idx)\n",
    "        att = self.attention_layer(embs)\n",
    "        logits = self.linear_layer(att)\n",
    "        return logits\n",
    "    \n",
    "    def get_loss(self, idx, targets, verbose=False):\n",
    "        logits = self.forward(idx)\n",
    "        B, T, C = logits.shape # Channel dimention: embedding dim\n",
    "        if verbose: print(idx.shape, '-->', logits.shape, '-->',logits.view(B*T, -1).shape,)\n",
    "        if verbose: print(targets.shape, '-->', targets.view(-1).shape,)\n",
    "        # in the first dimension we have all batches concatened, and all its instances\n",
    "        # in the second dimension we have the probabilities of each input\n",
    "        logits = logits.view(B*T, -1)\n",
    "        targets = targets.view(-1) # all the indexes, in one row\n",
    "\n",
    "        if verbose: print(f'One example: {logits[0,:3]}..... : target: {targets[0]}')\n",
    "\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        return loss\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, n_tokens):\n",
    "        # for all batch, parallel generate next tokens n times\n",
    "        for i in range(n_tokens):\n",
    "            logits = self(idx)\n",
    "            # focus on the last time step (because the forward predicts for all possible input len)\n",
    "            logits = logits[:, -1, :] # (batch_size, all tokens probability) - (B,C)\n",
    "            # apply softmax to get probability of the next token \n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            # sample based in the probability. (dont use only the most probable token)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1) only one token per batch\n",
    "            # print(idx.shape, idx_next.shape)\n",
    "            # concatenate in the history of tokens\n",
    "            idx = torch.cat((idx, idx_next), dim=1) #(B, T+1)\n",
    "        return idx\n",
    "    \n",
    "    def train(self, data, epochs, batch_size, verbose=False):\n",
    "        for epoch_i in range(epochs):\n",
    "            # random batch\n",
    "            batch_x, batch_y = get_batch(data, batch_size, CONTEXT_LENGTH)\n",
    "            if verbose: print('batch_x:', batch_x.shape, 'batch_y:', batch_y.shape)\n",
    "            # forward and loss \n",
    "            loss = self.get_loss(batch_x, batch_y) \n",
    "            self.optimizer.zero_grad(set_to_none=True) # already connected to the model weights\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            if epoch_i % 100 == 0:\n",
    "                print(f'Epoch {epoch_i+1}/{epochs} loss: {loss.item():.4f}')\n",
    "\n",
    "EMBEDDING_DIM = 32\n",
    "model = NanoGPT(VOCAB_SIZE, EMBEDDING_DIM, CONTEXT_LENGTH) \n",
    "model(train_batch_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000 loss: 4.1753\n",
      "Epoch 101/10000 loss: 3.0825\n",
      "Epoch 201/10000 loss: 2.7745\n",
      "Epoch 301/10000 loss: 2.7528\n",
      "Epoch 401/10000 loss: 2.7175\n",
      "Epoch 501/10000 loss: 2.6694\n",
      "Epoch 601/10000 loss: 2.8144\n",
      "Epoch 701/10000 loss: 2.5747\n",
      "Epoch 801/10000 loss: 2.4793\n",
      "Epoch 901/10000 loss: 2.4607\n",
      "Epoch 1001/10000 loss: 2.4438\n",
      "Epoch 1101/10000 loss: 2.6148\n",
      "Epoch 1201/10000 loss: 2.3679\n",
      "Epoch 1301/10000 loss: 2.4163\n",
      "Epoch 1401/10000 loss: 2.4617\n",
      "Epoch 1501/10000 loss: 2.4677\n",
      "Epoch 1601/10000 loss: 2.5190\n",
      "Epoch 1701/10000 loss: 2.4213\n",
      "Epoch 1801/10000 loss: 2.4631\n",
      "Epoch 1901/10000 loss: 2.4787\n",
      "Epoch 2001/10000 loss: 2.4451\n",
      "Epoch 2101/10000 loss: 2.5244\n",
      "Epoch 2201/10000 loss: 2.2764\n",
      "Epoch 2301/10000 loss: 2.4612\n",
      "Epoch 2401/10000 loss: 2.3444\n",
      "Epoch 2501/10000 loss: 2.3400\n",
      "Epoch 2601/10000 loss: 2.4088\n",
      "Epoch 2701/10000 loss: 2.4956\n",
      "Epoch 2801/10000 loss: 2.3229\n",
      "Epoch 2901/10000 loss: 2.3273\n",
      "Epoch 3001/10000 loss: 2.3319\n",
      "Epoch 3101/10000 loss: 2.2242\n",
      "Epoch 3201/10000 loss: 2.5390\n",
      "Epoch 3301/10000 loss: 2.2704\n",
      "Epoch 3401/10000 loss: 2.4251\n",
      "Epoch 3501/10000 loss: 2.4126\n",
      "Epoch 3601/10000 loss: 2.4293\n",
      "Epoch 3701/10000 loss: 2.4419\n",
      "Epoch 3801/10000 loss: 2.4407\n",
      "Epoch 3901/10000 loss: 2.2854\n",
      "Epoch 4001/10000 loss: 2.3797\n",
      "Epoch 4101/10000 loss: 2.2181\n",
      "Epoch 4201/10000 loss: 2.4045\n",
      "Epoch 4301/10000 loss: 2.2005\n",
      "Epoch 4401/10000 loss: 2.4432\n",
      "Epoch 4501/10000 loss: 2.2911\n",
      "Epoch 4601/10000 loss: 2.3362\n",
      "Epoch 4701/10000 loss: 2.4020\n",
      "Epoch 4801/10000 loss: 2.3955\n",
      "Epoch 4901/10000 loss: 2.3670\n",
      "Epoch 5001/10000 loss: 2.3675\n",
      "Epoch 5101/10000 loss: 2.3007\n",
      "Epoch 5201/10000 loss: 2.2929\n",
      "Epoch 5301/10000 loss: 2.2541\n",
      "Epoch 5401/10000 loss: 2.2941\n",
      "Epoch 5501/10000 loss: 2.3230\n",
      "Epoch 5601/10000 loss: 2.3909\n",
      "Epoch 5701/10000 loss: 2.4032\n",
      "Epoch 5801/10000 loss: 2.4731\n",
      "Epoch 5901/10000 loss: 2.4055\n",
      "Epoch 6001/10000 loss: 2.3002\n",
      "Epoch 6101/10000 loss: 2.3495\n",
      "Epoch 6201/10000 loss: 2.4395\n",
      "Epoch 6301/10000 loss: 2.4200\n",
      "Epoch 6401/10000 loss: 2.2488\n",
      "Epoch 6501/10000 loss: 2.3968\n",
      "Epoch 6601/10000 loss: 2.2608\n",
      "Epoch 6701/10000 loss: 2.2746\n",
      "Epoch 6801/10000 loss: 2.2611\n",
      "Epoch 6901/10000 loss: 2.3903\n",
      "Epoch 7001/10000 loss: 2.2245\n",
      "Epoch 7101/10000 loss: 2.3496\n",
      "Epoch 7201/10000 loss: 2.2154\n",
      "Epoch 7301/10000 loss: 2.1566\n",
      "Epoch 7401/10000 loss: 2.3377\n",
      "Epoch 7501/10000 loss: 2.2738\n",
      "Epoch 7601/10000 loss: 2.3627\n",
      "Epoch 7701/10000 loss: 2.3890\n",
      "Epoch 7801/10000 loss: 2.2791\n",
      "Epoch 7901/10000 loss: 2.2503\n",
      "Epoch 8001/10000 loss: 2.3439\n",
      "Epoch 8101/10000 loss: 2.2760\n",
      "Epoch 8201/10000 loss: 2.2517\n",
      "Epoch 8301/10000 loss: 2.2471\n",
      "Epoch 8401/10000 loss: 2.2915\n",
      "Epoch 8501/10000 loss: 2.2569\n",
      "Epoch 8601/10000 loss: 2.2144\n",
      "Epoch 8701/10000 loss: 2.4757\n",
      "Epoch 8801/10000 loss: 2.3096\n",
      "Epoch 8901/10000 loss: 2.2917\n",
      "Epoch 9001/10000 loss: 2.2729\n",
      "Epoch 9101/10000 loss: 2.3284\n",
      "Epoch 9201/10000 loss: 2.3377\n",
      "Epoch 9301/10000 loss: 2.3257\n",
      "Epoch 9401/10000 loss: 2.2204\n",
      "Epoch 9501/10000 loss: 2.4412\n",
      "Epoch 9601/10000 loss: 2.3783\n",
      "Epoch 9701/10000 loss: 2.2772\n",
      "Epoch 9801/10000 loss: 2.3265\n",
      "Epoch 9901/10000 loss: 2.2933\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 32\n",
    "model = NanoGPT(VOCAB_SIZE, EMBEDDING_DIM, CONTEXT_LENGTH, lr=1e-3) \n",
    "\n",
    "model = model.to('cuda')\n",
    "train_data = train_data.to('cuda')\n",
    "model.train(train_data, batch_size=32, epochs=10_000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thtsisomit hemame\n",
      "Ayis the, ayomis,\n",
      "Aue\n",
      "Sssse sth hu,\n",
      "Tis ostees it hantsp.\n",
      "\n",
      "It sthea tht wee ss Et sthot theered s testha y muehhotr?assolin le thal at t r,\n",
      "Br tlas lre mhese' w bto t th ay sumshedenorhas tshorat terrs ar set y Kuit.\n",
      "Ythhanedc tis w the.\n",
      "As t haro pth,\n",
      "Wiruthi'atheruborsweadt\n",
      "M at mt,\n",
      "\n",
      "Noirte jn she ay\n",
      "d,\n",
      "Atathe pass,\n",
      "Ihtha!You simeepat tlen\n",
      "Cd tu s wer amnbbl a t hane b' l,.\n",
      "\n",
      "Y tat mitis.\n",
      "I y hedtlvhee t sues lnthit Vhanert,\n",
      "Wan:\n",
      "E kdarh se\n",
      "Se fe hoir s;\n",
      "Vy, oras itieer t t,\n",
      "Sthileior se suossilhese ourr hen hass csins dhea than,\n",
      "Ar a an t;\n",
      "B a por a al,\n",
      "\n",
      "Tt\n",
      "Anon l wen,\n",
      "\n",
      "Sthe his perapawexr s ish capdepayiod tor vnince:\n",
      "Aiithato,\n",
      "Osedorathio s!\n",
      "To tasedre\n",
      "Uoa ste a fos.\n",
      "\n",
      "An olet hen l r s l\n",
      "Pan ku itamot go\n",
      "Kianhotayas P:\n",
      "\n",
      "Po c m ned than og sino trl:\n",
      "An to oatc di?\n",
      "Wb\n",
      "Stl t oua ye!\n",
      "\n",
      "Ase tod okelss ou,ay.Rth whe orirwe horease.\n",
      "Se,\n",
      "Ag.\n",
      "Dpisst t fe h y:\n",
      "Wirotithine\n",
      "Weanhayou har mso istind y Yotonifes initotie:, qua hatlan lcemwerudmen.\n",
      "Terserg t af,\n",
      "Tr o,\n",
      "Hnatrheyth \n"
     ]
    }
   ],
   "source": [
    "first_seed_token = torch.tensor([[0]], dtype=torch.long).to('cuda')  #torch.zeros((1, 1), dtype=torch.long)\n",
    "\n",
    "generated = model.generate(first_seed_token, n_tokens=1000).tolist()[0]\n",
    "print(tokenizer.decode(generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# if we pass vocab_size as embedding_dim, we have that each word in input\n",
    "# has am embedding that representes the probability of every other word in vocabulary(vocab size)\n",
    "# So we call logits\n",
    "model = BigramLanguageModel(VOCAB_SIZE, VOCAB_SIZE) \n",
    "pred_y = model(train_batch_x)\n",
    "# print(pred_y.shape) # for each sentence in the batch, we have the logits of each word (next word prediction)\n",
    "# print(train_batch_y.shape)\n",
    "# model.get_loss(train_batch_x, train_batch_y)\n",
    "model.generate(train_batch_x, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# if we pass vocab_size as embedding_dim, we have that each word in input\n",
    "# has am embedding that representes the probability of every other word in vocabulary(vocab size)\n",
    "# So we call logits\n",
    "pred_y = model(train_batch_x)\n",
    "# print(pred_y.shape) # for each sentence in the batch, we have the logits of each word (next word prediction)\n",
    "# print(train_batch_y.shape)\n",
    "model.generate(train_batch_x, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10]) --> torch.Size([4, 10, 65]) --> torch.Size([40, 65])\n",
      "torch.Size([4, 10]) --> torch.Size([40])\n",
      "One example: tensor([-0.4873,  0.1745,  2.0194], grad_fn=<SliceBackward0>)..... : target: 47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(4.7219, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_loss(train_batch_x, train_batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 60, 12, 55, 29, 28, 22, 57, 1, 48, 22, 45, 0, 8, 41, 30, 4, 13, 45, 23, 37, 28, 48, 37, 58, 56, 45, 57, 3, 28, 48, 64, 8, 29, 39, 34, 41, 25, 9, 21, 59, 25, 42, 15, 18, 34, 4, 41, 61, 30, 22, 42, 8, 23, 5, 22, 46, 37, 34, 23, 37, 28, 48, 46, 46, 46, 63, 57, 15, 30, 2, 49, 9, 42, 0, 61, 33, 60, 51, 2, 62, 37, 58, 13, 64, 61, 6, 13, 56, 45, 0, 39, 19, 25, 25, 56, 29, 60, 64, 5, 26]\n",
      "\n",
      "v?qQPJs jJg\n",
      ".cR&AgKYPjYtrgs$Pjz.QaVcM3IuMdCFV&cwRJd.K'JhYVKYPjhhhysCR!k3d\n",
      "wUvm!xYtAzw,Arg\n",
      "aGMMrQvz'N\n"
     ]
    }
   ],
   "source": [
    "first_seed_token = torch.tensor([[0]], dtype=torch.long)  #torch.zeros((1, 1), dtype=torch.long)\n",
    "\n",
    "generated = model.generate(first_seed_token, n_tokens=100).tolist()[0]\n",
    "print(generated)\n",
    "print(tokenizer.decode(generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 65])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[1,1,1,1,1,1,1,3]])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_layer = nn.Embedding(VOCAB_SIZE, embedding_dim=2)\n",
    "# print(embedding_layer)\n",
    "# _x = train_batch_x[0:1]\n",
    "# print(_x, _x.shape)\n",
    "# # convert each token in a float vector (embedding vector)\n",
    "# embedding_layer(_x) # each token has a associated embedding (like a lookup table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
